{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import sys\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UNK = \"<unk>\"  # token to map all out-of-vocabulary words (OOVs)\n",
    "UNKid = 0      # index for UNK\n",
    "epsilon=1e-100\n",
    "special = \"<s>\"\n",
    "smoothing_trans = 1e-2\n",
    "smoothing_trans_2 = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "        def __init__(self, state_list, observation_list,\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None,\n",
    "                    transition_proba_2 = None,smoothing_obs = 0.01):\n",
    "            print \"HMM creating with: \"\n",
    "            self.N = len(state_list)       # number of states\n",
    "            self.M = len(observation_list) # number of possible emissions\n",
    "            \n",
    "            #les differents labels\n",
    "            self.omega_Y = state_list\n",
    "            #les differents mots\n",
    "            self.omega_X = observation_list\n",
    "            #caractere special\n",
    "            #symbolise le debut d'un mot\n",
    "            self.omega_Y.append(\"@\")\n",
    "            \n",
    "            #creation des transitions\n",
    "            if transition_proba is None:\n",
    "                self.transition_proba = np.zeros( (self.N+1, self.N+1,self.N), float) \n",
    "            else:\n",
    "                self.transition_proba=transition_proba\n",
    "            \n",
    "            #creation des observations\n",
    "            if observation_proba is None:\n",
    "                self.observation_proba = np.zeros( (self.M, self.N), float) \n",
    "            else:\n",
    "                self.observation_proba=observation_proba\n",
    "            self.make_indexes() # build indexes, i.e the mapping between token and int\n",
    "            self.smoothing_obs = smoothing_obs \n",
    "            \n",
    "        def make_indexes(self):\n",
    "            \"\"\"Creates the reverse table that maps states/observations names\n",
    "            to their index in the probabilities array\"\"\"\n",
    "            #index des labels \n",
    "            self.Y_index = {}\n",
    "            for i in range(self.N+1):\n",
    "                self.Y_index[self.omega_Y[i]] =i\n",
    "                \n",
    "            #index des lettres\n",
    "            self.X_index = {}\n",
    "            for i in range(self.M):\n",
    "                self.X_index[self.omega_X[i]] = i\n",
    "      \n",
    "        def get_observationIndices( self, observations ):\n",
    "            \"\"\"return observation indices, i.e \n",
    "            return [self.O_index[o] for o in observations]\n",
    "            and deals with OOVs\n",
    "            \"\"\"\n",
    "            indices = zeros( len(observations), int )\n",
    "            k = 0\n",
    "            for o in observations:\n",
    "                if o in self.X_index:\n",
    "                    indices[k] = self.X_index[o]\n",
    "                else:\n",
    "                    indices[k] = UNKid\n",
    "                k += 1\n",
    "            return indices\n",
    "\n",
    "    \n",
    "        def data2indices(self, sent): \n",
    "            #associe a chaque caractere et label un unique identifiant\n",
    "            #par exemple : 'a' : 1\n",
    "            wordids = list()\n",
    "            tagids  = list()\n",
    "            for couple in sent:\n",
    "                wrd = couple[0]\n",
    "                tag = couple[1]\n",
    "                if wrd in self.X_index:\n",
    "                    wordids.append(self.X_index[wrd])\n",
    "                else:\n",
    "                    wordids.append(UNKid)\n",
    "                tagids.append(self.Y_index[tag])\n",
    "            return wordids,tagids\n",
    "            \n",
    "        def observation_estimation(self, pair_counts):\n",
    "            # calcul la probabilite d'observer une classe pour un caractere\n",
    "            #par exemple la classe 'y' pour le caractere 'c'\n",
    "            for pair in pair_counts:\n",
    "                wrd=pair[0]\n",
    "                tag=pair[1]\n",
    "                cpt=pair_counts[pair]\n",
    "                k = 0 # for <unk>\n",
    "                if wrd in self.X_index: \n",
    "                    k=self.X_index[wrd]\n",
    "                i = self.Y_index[tag]\n",
    "                self.observation_proba[k,i]=cpt\n",
    "            # normalize\n",
    "            self.observation_proba=self.observation_proba+self.smoothing_obs\n",
    "            self.observation_proba=self.observation_proba/self.observation_proba.sum(axis=0).reshape(1,self.N)\n",
    "            \n",
    "        \n",
    "        def transition_estimation(self, trans_counts,trans_count_bi):\n",
    "            #calcule la probabilite de passer dans un etat en conaissant les deux derniers etats\n",
    "            #par exemple (a,b)=> b\n",
    "            for pair in trans_counts:\n",
    "                #l'etat courant a t\n",
    "                i=self.Y_index[pair[1]]\n",
    "                #l'etat a t-2\n",
    "                j=self.Y_index[pair[0][0]]\n",
    "                #l'etat a t-1\n",
    "                k=self.Y_index[pair[0][1]]\n",
    "                #normalisation\n",
    "                self.transition_proba[j,k,i]=float(trans_counts[pair])/float(trans_count_bi[pair[0]])\n",
    "\n",
    "        def init_estimation(self, init_counts,init_counts2):\n",
    "            #comptes d'initialisation\n",
    "            \n",
    "            #indice du caractere special\n",
    "            indice_empty = self.Y_index[\"@\"]\n",
    "            for init in init_counts:\n",
    "                i=self.Y_index[init]\n",
    "                #cas du tout premier caractere des mots, comme pas de passé\n",
    "                #on note le passe (@,@)\n",
    "                self.transition_proba[indice_empty,indice_empty,i]=float(init_counts[init])/float(sum(init_counts.values()))\n",
    "            \n",
    "            #cas du second caractere des mots\n",
    "            for p in init_counts2:\n",
    "                old=self.Y_index[p[0]]\n",
    "                new=self.Y_index[p[1]]\n",
    "                #cas du tout premier caractere des mots, comme un seul passé\n",
    "                #on note le passe (@,@)\n",
    "                self.transition_proba[indice_empty,old,new]=float(init_counts2[p])/float(init_counts[p[0]])\n",
    "        \n",
    "        def supervised_training(self, cpairs, ctrans, ctrans2 ,cinits, cinits2):\n",
    "            \"\"\" Train the HMM's parameters. This function wraps everything\"\"\"\n",
    "            self.observation_estimation(cpairs)\n",
    "            self.transition_estimation(ctrans,ctrans2)\n",
    "            self.init_estimation(cinits,cinits2)\n",
    "            #indices pour eviter de calculer des transitions a zeros\n",
    "            self.solo = np.zeros( (self.N,), float ) \n",
    "            for tags in ctags:\n",
    "                self.solo[self.Y_index[tags]] = ctags[tags]\n",
    "            self.solo=self.solo/sum(self.solo)\n",
    "            print(self.solo)\n",
    "            #contient pour chaque position dans alpha_2 les deux caracteres associees\n",
    "            #par exemple : (a,b) : 2\n",
    "            self.Y_index_2 = {}\n",
    "            count = 0 \n",
    "            for e in self.omega_Y:\n",
    "                for z in self.omega_Y:\n",
    "                    self.Y_index_2[(e,z)]= count\n",
    "                    count +=1\n",
    "                \n",
    "        def get_trans(self,k,indi_2):\n",
    "            #indi_2 : vers nouvel etat\n",
    "            # k :ancien etat\n",
    "            return  self.transition_proba[k,indi_2]\n",
    "    \n",
    "        def find_indices(self,k):\n",
    "            #renvoie les indices a parcourir en fonction de la position dans le mot\n",
    "            #si premier ou deuxieme caracter: le passe est limite et on renvoie @\n",
    "            #sinon le passe peut etre l'ensemble des 26 labels\n",
    "            if k == 0 or k==-1:\n",
    "                return set(['@'])\n",
    "            return self.omega_Y[0:26]\n",
    "        \n",
    "        \n",
    "        def viverbit(self,mots):\n",
    "            #algo de viterbi\n",
    "            if len(mots) <=1:\n",
    "                #traite le mot est compose d un seul caractere\n",
    "                return 0,mots\n",
    "            #contient le chemin qui a permis d'arriver dans chaque etat\n",
    "            #au debut, pas de passé donc seul moyen d'arriver dans un etat est de passer\n",
    "            #par les etats @ et @\n",
    "            path_to = {('@','@') : []}\n",
    "            #contient les probabs associes a chaque etat pour chaque mot\n",
    "            alpha_2 = np.zeros((self.N+1,self.N+1,len(mots)+1))\n",
    "            '''for i in range(self.N+1):\n",
    "                alpha_2[:,i,0] = np.ones(self.N+1)'''\n",
    "            #intialisation pour le tout premier caracteres (@)\n",
    "            alpha_2[:,:,0] = np.ones((self.N+1,self.N+1))\n",
    "            #pour chaque lettre (+1) car on commence par @\n",
    "            for j in range(1,len(mots)+1):\n",
    "                temp_path = {}\n",
    "                index = 0\n",
    "                #cas qui correspond a juste avant la premiere lettre\n",
    "                if j==0:\n",
    "                    index = self.X_index['@']\n",
    "                else:\n",
    "                    index = self.X_index[mots[j-1]]\n",
    "                \n",
    "                #trouve les caracteres possibles pour la position (j-1) : (-1) a cause du premier caractere @\n",
    "                indices = self.find_indices(j-1)\n",
    "                for i in indices:\n",
    "                    corr_indices = self.find_indices(j)\n",
    "                    indice_i = self.Y_index[i]\n",
    "                    \n",
    "                    #boucle sur tous les etats possibles pour le caractere i\n",
    "                    for co in corr_indices:\n",
    "                        indice_j= self.Y_index[co]\n",
    "                        valeur_max = -10000000\n",
    "                        back = 0\n",
    "                        #pour chaque etat, calcule la probabilite en fonction des deux derniers etat\n",
    "                        for t in self.find_indices(j-2):\n",
    "                            tmp = alpha_2[self.Y_index[t],self.Y_index[i],j-1] * self.transition_proba[self.Y_index[t],indice_i,indice_j] * self.observation_proba[index,indice_j]\n",
    "                            if tmp > valeur_max:\n",
    "                                #calcule de la valeur max\n",
    "                                valeur_max = tmp\n",
    "                                back = t\n",
    "                        #sauvegarde du max et du chemin maximisant pour arriver dans cet etat\n",
    "                        alpha_2[self.Y_index[i],self.Y_index[co],j] = valeur_max\n",
    "                        temp_path[i,co] = path_to[back,i] + [co]\n",
    "                path_to = temp_path\n",
    "            #backtrack\n",
    "            #recuperation de la proba maximale\n",
    "            proba = np.max(alpha_2[:,:,len(mots)])\n",
    "            #recuperation du couple associe a la valeur maximale\n",
    "            chemin_max = np.argmax(alpha_2[:,:,len(mots)])\n",
    "            #recuperation du chemin\n",
    "            i,co = self.Y_index_2.keys()[self.Y_index_2.values().index(chemin_max)]\n",
    "            return proba,path_to[i,co]\n",
    "                 \n",
    "        def evaluate(self,test_data):\n",
    "            #fonction d'evaluation\n",
    "            #calcul differentes valeurs comme le taux de correction\n",
    "            #le taux d'erreurs...\n",
    "            \n",
    "            #taux d'erreur brut\n",
    "            errors = 0\n",
    "            #nombre total de caracteres\n",
    "            total = 0\n",
    "            #taux d'erreur sur l'ensemble de test\n",
    "            erreur_2 = 0\n",
    "            \n",
    "            #nombre de correction\n",
    "            correction = 0\n",
    "            correction_totale = 0\n",
    "            for i in range(len(test_data)):\n",
    "                if i%100==0:\n",
    "                    print(\"Remaining : {}\".format(len(test_data)-i))\n",
    "                p,res = self.viverbit(map(operator.itemgetter(0), test_data[i]))\n",
    "                for a,b in zip(res,test_data[i]):\n",
    "                    if(b[1]!=b[0] and b[1] ==a):\n",
    "                        correction +=1\n",
    "                    correction_totale +=1\n",
    "                erreur_2 += sum([a!=b for a,b in test_data[i]])\n",
    "                errors += sum([a!=b[1] for a,b in zip(res,test_data[i])])\n",
    "                total += len(res)\n",
    "            print(\"################# Resultats du HMM d'ordre 1 #################\")\n",
    "            print(\"Percentage of errors : {0:.2f}%\".format(((errors/float(total))*100.0)))\n",
    "            print(\"Taux d erreur brut : {0:.2f}%\".format(((erreur_2/float(total))*100.0)))\n",
    "            print(\"Taux de correction : {0:.2f}%\".format(((correction/float(correction_totale))*100.0)))\n",
    "            print(\"Nombre de corrections {} vs nombre de bonnes corrections {}\".format(correction_totale,correction))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de phrases de train = 27184\n",
      "Nombre de phrases de test  = 1501\n",
      "Nombre de mots  : 26\n",
      "Nombre de tags  : 26\n",
      "Nombre de paires: 128\n",
      "Nombre de trans : 2464 / 144\n",
      "Nombre de init. : 25\n",
      "Vocabulaire :26\n"
     ]
    }
   ],
   "source": [
    "def make_counts(corpus):\n",
    "    \"\"\" \n",
    "    Build different count tables to train a HMM. Each count table is a dictionnary. \n",
    "    Returns: \n",
    "    * c_words: word counts\n",
    "    * c_tags: tag counts\n",
    "    * c_pairs: count of pairs (word,tag)\n",
    "    * c_transitions: count of tag bigram \n",
    "    * c_inits: count of tag found in the first position\n",
    "    \"\"\"\n",
    "    c_words = dict()\n",
    "    c_tags = dict()\n",
    "    c_pairs= dict()\n",
    "    c_transitions = dict()\n",
    "    c_transitions2 = dict()\n",
    "    c_inits = dict()\n",
    "    c_inits2 = dict()\n",
    "    for sent in corpus:\n",
    "        # we use i because of the transition counts\n",
    "        for i in range(len(sent)):\n",
    "            couple=sent[i]\n",
    "            wrd = couple[0]\n",
    "            tag = couple[1]\n",
    "            # word counts\n",
    "            if wrd in c_words:\n",
    "                c_words[wrd]=c_words[wrd]+1\n",
    "            else:\n",
    "                c_words[wrd]=1\n",
    "            # tag counts\n",
    "            if tag in c_tags:\n",
    "                c_tags[tag]=c_tags[tag]+1\n",
    "            else:\n",
    "                c_tags[tag]=1\n",
    "            # observation counts\n",
    "            if couple in c_pairs:\n",
    "                c_pairs[couple]=c_pairs[couple]+1\n",
    "            else:\n",
    "                c_pairs[couple]=1\n",
    "            # i >  0 -> transition counts\n",
    "            if i > 0:\n",
    "                trans = (sent[i-1][1],tag)\n",
    "                if trans in c_transitions2:\n",
    "                    c_transitions2[trans]=c_transitions2[trans]+1\n",
    "                else:\n",
    "                    c_transitions2[trans]=1\n",
    "            if i > 1:\n",
    "                trans = ((sent[i-2][1],sent[i-1][1]),tag)\n",
    "                if trans in c_transitions:\n",
    "                    c_transitions[trans]=c_transitions[trans]+1\n",
    "                else:\n",
    "                    c_transitions[trans]=1\n",
    "            # i == 0 -> counts for initial states\n",
    "            if i==0:\n",
    "                if tag in c_inits:\n",
    "                    c_inits[tag]=c_inits[tag]+1\n",
    "                else:\n",
    "                    c_inits[tag]=1\n",
    "            if i == 1:\n",
    "                cle = (sent[i-1][1],tag)\n",
    "                if cle in c_inits2:\n",
    "                    c_inits2[cle] +=1\n",
    "                else:\n",
    "                    c_inits2[cle]=1\n",
    "                    \n",
    "    return c_words,c_tags,c_pairs, c_transitions, c_inits, c_transitions2,c_inits2\n",
    "def make_vocab(c_words, threshold):\n",
    "    \"\"\" \n",
    "    return a vocabulary by thresholding word counts. \n",
    "    inputs: \n",
    "    * c_words : a dictionnary that maps word to its counts\n",
    "    * threshold: count must be >= to the threshold to be included\n",
    "    \n",
    "    returns: \n",
    "    * a word list\n",
    "    \"\"\"\n",
    "    voc = list()\n",
    "    for w in c_words:\n",
    "        if c_words[w] >= threshold:\n",
    "            voc.append(w)\n",
    "    return voc\n",
    "import cPickle\n",
    "from pprint import pprint\n",
    "\n",
    "with open(\"typos-data/test10.pkl\", \"rb\") as input_file:\n",
    "    test = cPickle.load(input_file)\n",
    "    \n",
    "with open(\"typos-data/train20.pkl\", \"rb\") as input_file:\n",
    "    train = cPickle.load(input_file)\n",
    "print \"Nombre de phrases de train = \"+str(len(train))\n",
    "print \"Nombre de phrases de test  = \"+str(len(test))\n",
    "cwords,ctags,cpairs,ctrans,cinits, ctrans2,cinits2 = make_counts(train)\n",
    "print \"Nombre de mots  : \"+str(len(cwords))\n",
    "print \"Nombre de tags  : \"+str(len(ctags))\n",
    "print \"Nombre de paires: \"+str(len(cpairs))\n",
    "print \"Nombre de trans : \"+str(len(ctrans))+ \" / \"+ str(12*12)\n",
    "print \"Nombre de init. : \"+str(len(cinits))\n",
    "vocab = make_vocab(cwords,10)\n",
    "print \"Vocabulaire :\"+str(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation du hmm\n",
      "HMM creating with: \n",
      "[ 0.07384321  0.03371526  0.0145519   0.12630328  0.03187665  0.01905125\n",
      "  0.02319932  0.07621247  0.04683214  0.00417797  0.00073993  0.02648041\n",
      "  0.04457499  0.08374627  0.06842455  0.00106878  0.02274341  0.06780421\n",
      "  0.05777409  0.027751    0.09666136  0.01554594  0.01339342  0.02071048\n",
      "  0.00194324  0.00087446]\n"
     ]
    }
   ],
   "source": [
    "print(\"Creation du hmm\")\n",
    "hmm = HMM(state_list=ctags.keys(), observation_list=cwords.keys(),\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None,\n",
    "                 smoothing_obs = 0.001)\n",
    "hmm.supervised_training( cpairs, ctrans, ctrans2 ,cinits, cinits2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining : 1501\n",
      "Remaining : 1401\n",
      "Remaining : 1301\n",
      "Remaining : 1201\n",
      "Remaining : 1101\n",
      "Remaining : 1001\n",
      "Remaining : 901\n",
      "Remaining : 801\n",
      "Remaining : 701\n",
      "Remaining : 601\n",
      "Remaining : 501\n",
      "Remaining : 401\n",
      "Remaining : 301\n",
      "Remaining : 201\n",
      "Remaining : 101\n",
      "Remaining : 1\n",
      "################# Resultats du HMM d'ordre 1 #################\n",
      "Percentage of errors : 4.25%\n",
      "Taux d erreur brut : 10.18%\n",
      "Taux de correction : 7.70%\n",
      "Nombre de corrections 7320 vs nombre de bonnes corrections 564\n"
     ]
    }
   ],
   "source": [
    "#calcul du taux d'erreur\n",
    "hmm.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple d'appel de viterbi pour les 10 premieres donnees de test : \n",
      "###############################################################\n",
      "the ------------------> the & 0.0371518198204\n",
      "leftist ------------------> leftist & 1.93716052036e-06\n",
      "is ------------------> is & 0.0119598510127\n",
      "too ------------------> too & 0.000663231296692\n",
      "far ------------------> far & 0.000513967787936\n",
      "gone ------------------> gone & 6.1260238484e-06\n",
      "for ------------------> for & 0.00777076665394\n",
      "that ------------------> that & 0.00377257851937\n",
      "his ------------------> his & 0.000965235466778\n",
      "reeljhgs ------------------> reelings & 5.21631519622e-12\n"
     ]
    }
   ],
   "source": [
    "print(\"Exemple d'appel de viterbi pour les 10 premieres donnees de test : \")\n",
    "print(\"###############################################################\")\n",
    "for i in range(10):\n",
    "    entree = \"\".join([a[0] for a in test[i]])\n",
    "    proba,solution = hmm.viverbit(entree)\n",
    "    solution = \"\".join(solution)\n",
    "    print(\"{} ------------------> {} & {}\".format(entree,solution,proba))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
